{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Testcontainers with FastAPI and asyncpg","text":"<p>When I first got to know about testcontainers, I wanted to learn how to integrate it with <code>asyncpg</code>, an asynchronous driver for PostgreSQL, for testing asynchronous routes in FastAPI. In an initial reference search, I found this article by Guilherme, and based on his article, I decided to write this example application.</p> <p>You can check the complete repository here.</p> <p>TL;DR: The full <code>conftest.py</code> setup is available here.</p>"},{"location":"#testcontainers","title":"Testcontainers","text":"<p>Testcontainers is an open-source library for providing lightweight instances of anything that can run in a Docker container. It was originally implemented for .NET, Go, Java, and Node.js but has since been extended to other programming languages through community projects, including Python: testcontainer-python.</p> <p>Below is a documentation example of how to use an instance of PostgreSQL, which uses <code>psycopg2</code> as the default driver.</p> <pre><code>&gt;&gt;&gt; from testcontainers.postgres import PostgresContainer\n&gt;&gt;&gt; import sqlalchemy\n\n&gt;&gt;&gt; with PostgresContainer(\"postgres:16\") as postgres:\n...    psql_url = postgres.get_connection_url()\n...    engine = sqlalchemy.create_engine(psql_url)\n...    with engine.begin() as connection:\n...        version, = connection.execute(sqlalchemy.text(\"SELECT version()\")).fetchone()\n&gt;&gt;&gt; version\n'PostgreSQL 16...'\n</code></pre>"},{"location":"#context","title":"Context","text":"<p>The objective of this repository is to test asynchronous FastAPI endpoints using PostgreSQL as a database. To achieve that, besides the <code>testcontainers</code>, it uses <code>pytest</code> and <code>anyio</code>, which provides built-in support for testing applications in the form of a pytest plugin. The choice of <code>anyio</code> over <code>pytest-asyncio</code> is because FastAPI is based on Starlette, which uses AnyIO, so we don't need to install an additional package here.</p> <p>The development of the API routes uses aiosqlite, the async driver for SQLite.</p> <p>Below are all the dependencies used to run the example.</p> requirements.txt<pre><code>aiosqlite&gt;=0.20.0\nasyncpg&gt;=0.30.0\nfastapi[standard]&gt;=0.115.6\npytest&gt;=8.3.4\nsqlalchemy&gt;=2.0.36\ntestcontainers&gt;=4.8.2\n</code></pre> <p>The repository README contains all the steps to run it locally using uv.</p> <p>Below is how the example is structured:</p> <pre><code>.\n\u251c\u2500\u2500 src # (1)\n\u2502   \u251c\u2500\u2500 app.py\n\u2502   \u251c\u2500\u2500 database.py\n\u2502   \u251c\u2500\u2500 models.py\n\u2502   \u2514\u2500\u2500 schemas.py\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 conftest.py # (2)\n    \u2514\u2500\u2500 test_routes.py\n</code></pre> <ol> <li>Where the example API is written using FastAPI.</li> <li>Where API test fixtures are written, from the PostgreSQL instance to the client. You can learn more about the <code>conftest.py</code> file in the pytest docs.</li> </ol>"},{"location":"#api-routes-implementation","title":"API routes implementation","text":"<p>This section will show the endpoints created for later tests. For this example, three simple routes were created to simulate a ticketing sell system:</p> <ul> <li><code>GET /tickets/all</code> - To list all the available tickets</li> <li><code>POST /tickets/create</code> - To create a new ticket to sell</li> <li><code>POST /tickets/buy</code> - To buy an available ticket to sell</li> </ul> <p>In the database, besides the <code>id</code> field, the ticket table has: a <code>price</code> field, a boolean field <code>is_sold</code> to identify if it's sold or not, and a <code>sold_to</code> field to identify who the ticket was sold to. The <code>models.py</code> file contains this information, using the <code>SQLAlchemy</code> ORM.</p> src/models.py<pre><code>from sqlalchemy.ext.asyncio import AsyncAttrs\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n\n\nclass Base(DeclarativeBase, AsyncAttrs):\n    pass\n\n\nclass Ticket(Base):\n    __tablename__ = 'tickets'\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    price: Mapped[int]\n    is_sold: Mapped[bool] = mapped_column(default=False)\n    sold_to: Mapped[str] = mapped_column(nullable=True, default=None)\n</code></pre> <p>The <code>database.py</code> contains the database connection, as well as the <code>get_session()</code> generator, responsible for creating asynchronous sessions to perform transactions in the database.</p> src/database.py<pre><code>from collections.abc import AsyncGenerator\n\nfrom sqlalchemy.ext.asyncio import (\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\n\nDATABASE_URL = 'sqlite+aiosqlite:///db.sqlite3'\n\nengine = create_async_engine(DATABASE_URL, echo=True)\n\nAsyncSessionLocal = async_sessionmaker(\n    bind=engine,\n    expire_on_commit=False,\n    class_=AsyncSession,\n)\n\n\nasync def get_session() -&gt; AsyncGenerator[AsyncSession, None]:\n    async with AsyncSessionLocal() as session:\n        yield session\n</code></pre> <p>The last file before creating the routes is the <code>schemas.py</code>, which will contain all the Pydantic models.</p> src/schemas.py<pre><code>from pydantic import BaseModel\n\n\nclass TicketBase(BaseModel):\n    price: int\n    is_sold: bool = False\n    sold_to: str | None = None\n\n\nclass TicketResponse(TicketBase):\n    id: int\n\n\nclass TicketRequestCreate(TicketBase):\n    pass\n\n\nclass TicketRequestBuy(BaseModel):\n    ticket_id: int\n    user: str\n\n\nclass ListTickets(BaseModel):\n    tickets: list[TicketResponse]\n</code></pre> <p>The previous three files are imported in <code>app.py</code>, which contains the API routes for this example. As mentioned earlier, although the objective is to test the endpoints with a PostgreSQL database, the development of the API uses SQLite to avoid the need for a PostgreSQL instance running constantly.</p> <p>To keep things simple and avoid database migrations, the database creation is handled using lifespan events. This guarantees that every time we run the application, a database will be created if it doesn't already exist.</p> src/app.py<pre><code>from contextlib import asynccontextmanager\nfrom http import HTTPStatus\nfrom typing import Annotated\n\nfrom fastapi import Depends, FastAPI, HTTPException\nfrom sqlalchemy import and_, select, update\n\nfrom src.database import AsyncSession, engine, get_session\nfrom src.models import Base, Ticket\nfrom src.schemas import (\n    ListTickets,\n    TicketRequestBuy,\n    TicketRequestCreate,\n    TicketResponse,\n)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n        yield\n    await engine.dispose()\n\n\napp = FastAPI(lifespan=lifespan)\n</code></pre> <p>Below are the route implementations, as well as the <code>SessionDep</code> to be used as dependency injection in each route.</p> src/app.py<pre><code>...\n\nSessionDep = Annotated[AsyncSession, Depends(get_session)]\n\n\n@app.get('/tickets/all', response_model=ListTickets)\nasync def get_all_tickets(session: SessionDep):\n    async with session.begin():\n        tickets = await session.scalars(select(Ticket))\n        all_tickets = tickets.all()\n\n    return {'tickets': all_tickets}\n\n\n@app.post(\n    '/tickets/create',\n    response_model=TicketResponse,\n    status_code=HTTPStatus.CREATED,\n)\nasync def create_ticket(session: SessionDep, ticket_in: TicketRequestCreate):\n    new_ticket = Ticket(**ticket_in.model_dump())\n\n    async with session.begin():\n        session.add(new_ticket)\n\n    return new_ticket\n\n\n@app.post('/tickets/buy', response_model=TicketResponse)\nasync def get_ticket_by_id(session: SessionDep, ticket_in: TicketRequestBuy):\n    async with session.begin():\n        ticket_db = await session.scalar(\n            select(Ticket).where(Ticket.id == ticket_in.ticket_id)\n        )\n\n        if not ticket_db:\n            raise HTTPException(\n                status_code=HTTPStatus.NOT_FOUND, detail='Ticket was not found'\n            )\n\n        stm = (\n            update(Ticket)\n            .where(\n                and_(\n                    Ticket.id == ticket_in.ticket_id,\n                    Ticket.is_sold == False,  # noqa: E712\n                )\n            )\n            .values(is_sold=True, sold_to=ticket_in.user)\n        )\n\n        ticket_updated = await session.execute(stm)\n\n        if ticket_updated.rowcount == 0:\n            raise HTTPException(\n                status_code=HTTPStatus.CONFLICT,\n                detail='Ticket has already been sold',\n            )\n\n    return ticket_db\n</code></pre> <p>Now, by running the command below in the terminal, the application should be available at <code>http://127.0.0.1:8000</code>.</p> pipuv <pre><code>python -m fastapi dev src/app.py\n</code></pre> <pre><code>uv run -m fastapi dev src/app.py\n</code></pre>"},{"location":"#tests-workflow","title":"Tests workflow","text":"<p>To use PostgreSQL in the tests, the testcontainer will be set up in <code>conftest.py</code>, along with the database session and the client required to test the endpoints.</p> <p>Below is a simple diagram illustrating how it works for each test, where each block represents a different function.</p> <pre><code>flowchart LR\n    %% Nodes for fixtures\n    postgres_container[\"postgres_container\"]\n    async_session[\"async_session\"]\n    async_client[\"async_client\"]\n    test[\"Test\"]\n\n    %% Subgraph for dependencies\n    subgraph Fixtures in conftest.py\n        direction LR\n        postgres_container --&gt; async_session\n        async_session --&gt; async_client\n    end\n\n    %% Arrows from async_client to test blocks\n    async_client --&gt; test\n    async_session --&gt; test\n\n    %% Style the nodes with rounded corners\n    classDef fixtureStyle rx:10, ry:10;\n\n    %% Style the nodes\n    class postgres_container,async_session,async_client,test fixtureStyle;</code></pre> <p>The <code>postgres_container</code> will be passed to <code>async_session</code>, which will be used in both <code>async_client</code> and directly in the tests, in cases where we need to transact directly with the database.</p>"},{"location":"#creating-the-test-fixtures","title":"Creating the test fixtures","text":"<p>The first fixture inserted in <code>conftest.py</code> is the <code>anyio_backend</code>, highlighted in the code below. This function will be used in <code>postgres_container</code> and marked for the AnyIO pytest plugin, as well as setting <code>asyncio</code> as the backend to run the tests. This function was not included in the previous diagram because it is an AnyIO specification. You can check more details about it here.</p> tests/conftest.py<pre><code>from collections.abc import AsyncGenerator, Generator\nfrom typing import Literal\n\nimport pytest\nfrom httpx import ASGITransport, AsyncClient\nfrom sqlalchemy.ext.asyncio import (\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\nfrom testcontainers.postgres import PostgresContainer\n\nfrom src.app import app\nfrom src.database import get_session\nfrom src.models import Base\n\n\n@pytest.fixture\ndef anyio_backend() -&gt; Literal['asyncio']:\n    return 'asyncio'\n</code></pre> <p>Now, in the <code>postgres_container</code>, the <code>anyio_backend</code> is passed, and all the tests that use the <code>postgres_container</code> as a fixture at any level will be marked to run asynchronously.</p> <p>Below is the <code>postgres_container</code> function, which will be responsible for creating the <code>PostgresContainer</code> instance from <code>testcontainers</code>. The <code>asyncpg</code> driver is passed as an argument to specify that it will be the driver used.</p> tests/conftest.py<pre><code>@pytest.fixture\ndef postgres_container(\n    anyio_backend: Literal['asyncio'],\n) -&gt; Generator[PostgresContainer, None, None]:\n    with PostgresContainer('postgres:16', driver='asyncpg') as postgres:\n        yield postgres\n</code></pre> <p>The <code>async_session</code> takes the connection URL from the <code>PostgresContainer</code> object returned by the <code>postgres_container</code> function and uses it to create the tables inside the database, as well as the session that will handle all interactions with the PostgreSQL instance created. The function will return and persist a session to be used, and then restore the database for the next test by deleting the tables.</p> tests/conftest.py<pre><code>@pytest.fixture\nasync def async_session(\n    postgres_container: PostgresContainer,\n) -&gt; AsyncGenerator[AsyncSession, None]:\n    db_url = postgres_container.get_connection_url()\n    async_engine = create_async_engine(db_url)\n\n    async with async_engine.begin() as conn:\n        await conn.run_sync(Base.metadata.drop_all)\n        await conn.run_sync(Base.metadata.create_all)\n\n    async_session = async_sessionmaker(\n        bind=async_engine,\n        expire_on_commit=False,\n        class_=AsyncSession,\n    )\n\n    async with async_session() as session:\n        yield session\n\n    await async_engine.dispose()\n</code></pre> <p>The last fixture is the <code>async_client</code> function, which will create the <code>AsyncClient</code>, directly imported from HTTPX, and provide it to make requests to our endpoints. Here, the session provided by <code>async_session</code> will override the session originally used in our app as a dependency injection while the client is being used.</p> tests/conftest.py<pre><code>@pytest.fixture\nasync def async_client(\n    async_session: AsyncSession,\n) -&gt; AsyncGenerator[AsyncClient, None]:\n    app.dependency_overrides[get_session] = lambda: async_session\n    _transport = ASGITransport(app=app)\n\n    async with AsyncClient(\n        transport=_transport, base_url='http://test', follow_redirects=True\n    ) as client:\n        yield client\n\n    app.dependency_overrides.clear()\n</code></pre>"},{"location":"#running-the-tests","title":"Running the tests","text":"<p>With all the test fixtures created, it's now possible to write and run the tests.</p> <p>Below are the test examples for the <code>GET /tickets/all</code>. The first one inserts 3 records in the table using the <code>async_session</code> and then asserts if the response has a 200 status and the list returned has a length of 3. The second one tests the case where there are no records yet in the database, as the response must return a 200 status and an empty list.</p> tests/test_routes.py<pre><code>from http import HTTPStatus\n\nfrom httpx import AsyncClient\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom src.models import Ticket\n\n\nasync def test_get_all_tickets_success(\n    async_session: AsyncSession, async_client: AsyncClient\n):\n    ticket_data_list = [\n        {'price': 100, 'is_sold': False, 'sold_to': None},\n        {'price': 200, 'is_sold': True, 'sold_to': 'Buyer1'},\n        {'price': 150, 'is_sold': False, 'sold_to': None},\n    ]\n\n    expected_len = len(ticket_data_list)\n\n    tickets = [Ticket(**data) for data in ticket_data_list]\n\n    async with async_session.begin():\n        async_session.add_all(tickets)\n\n    response = await async_client.get('/tickets/all')\n\n    assert response.status_code == HTTPStatus.OK\n    assert len(response.json()['tickets']) == expected_len\n\n\nasync def test_get_all_tickets_when_empty(async_client: AsyncClient):\n    response = await async_client.get('/tickets/all')\n\n    assert response.status_code == HTTPStatus.OK\n    assert response.json()['tickets'] == []\n</code></pre> <p>In total there are 6 test, and the rest of them has the same logic. Their full implementations can be checked in the repository.</p> <p>Adding the following setting in <code>pyproject.toml</code> or <code>pytest.ini</code> will inform pytest to add the root directory to the Python search path when running tests.</p> pyproject.tomlpytest.ini <pre><code>[tool.pytest.ini_options]\npythonpath = '.'\n</code></pre> <pre><code>[pytest]\npythonpath = .\n</code></pre> <p>Now, if we run the following command in the terminal...</p> pipuv <pre><code>pytest -vv\n</code></pre> <pre><code>uv run pytest -vv\n</code></pre> <p>...we will see something similar to this:</p> <pre><code>tests/test_routes.py::test_get_all_tickets_success PASSED               [ 16%]\ntests/test_routes.py::test_get_all_tickets_when_empty PASSED            [ 33%]\ntests/test_routes.py::test_create_ticket_success PASSED                 [ 50%]\ntests/test_routes.py::test_buy_ticket_success PASSED                    [ 66%]\ntests/test_routes.py::test_buy_ticket_when_ticket_not_found PASSED      [ 83%]\ntests/test_routes.py::test_buy_ticket_when_already_sold PASSED          [100%]\n\n============================================= 6 passed in 12.31s =============================================\n</code></pre> <p>Although all the tests are very simple, it took an average of more than two seconds for each one of them to execute. This happens because for each test, a new PostgreSQL Docker instance is being created, as shown in Tests workflow.</p> <p>To make the tests faster, one option is to create just one PostgreSQL Docker instance and use it for all the tests by configuring the <code>@pytest.fixture(scope='')</code>.</p>"},{"location":"#the-pytest-fixture-scope","title":"The pytest fixture scope","text":"<p>Fixtures requiring network access depend on connectivity and are usually time-expensive to create. By setting the <code>scope</code> in <code>@pytest.fixture</code>, we can tell pytest how to manage the fixture's creation and reuse.</p> <p>Fixtures are created when first requested by a test and are destroyed based on their <code>scope</code>. Some of the scope options that can be set are:</p> <ul> <li><code>function</code>: the default scope, the fixture is destroyed at the end of the test.</li> <li><code>class</code>: the fixture is destroyed during the teardown of the last test in the class.</li> <li><code>module</code>: the fixture is destroyed during the teardown of the last test in the module.</li> <li><code>package</code>: the fixture is destroyed during the teardown of the last test in the package.</li> <li><code>session</code>: the fixture is destroyed at the end of the test session.</li> </ul> <p>As we want to create just one Docker instance and reuse it for all the tests, we changed the <code>@pytest.fixture</code> in the <code>conftest.py</code> file in the following highlighted lines.</p> conftest.py<pre><code>@pytest.fixture(scope='session')\ndef anyio_backend() -&gt; Literal['asyncio']:\n    return 'asyncio'\n\n\n@pytest.fixture(scope='session')\ndef postgres_container(\n    anyio_backend: Literal['asyncio'],\n) -&gt; Generator[PostgresContainer, None, None]:\n    with PostgresContainer('postgres:16', driver='asyncpg') as postgres:\n        yield postgres\n</code></pre> <p>Now, every time we run the tests, we will follow a workflow similar to the one below, where the <code>postgres_container</code> fixture is created only once at the beginning of the test session and is reused in all other fixtures. The <code>async_session</code> and <code>async_client</code> fixtures are still created and destroyed for each test. The <code>postgres_container</code> fixture is destroyed only after all the tests have finished.</p> <pre><code>flowchart LR\n    %% Nodes for fixtures\n    postgres_container[\"postgres_container\"]\n    async_session[\"async_session\"]\n    async_client[\"async_client\"]\n    test[\"Test 1\"]\n    async_session_2[\"async_session\"]\n    async_client_2[\"async_client\"]\n    test_2[\"Test 2\"]\n    async_session_n[\"async_session\"]\n    async_client_n[\"async_client\"]\n    test_n[\"Test N\"]\n\n    subgraph All fixtures\n        direction LR\n\n        subgraph Function fixtures\n            direction LR\n            async_session --&gt; async_client\n            async_session_2 --&gt; async_client_2\n            async_session_n --&gt; async_client_n\n        end\n\n        subgraph Session Fixture\n            direction LR\n            postgres_container --&gt; async_session\n            postgres_container --&gt; async_session_2\n            postgres_container --&gt; async_session_n\n        end\n    end\n\n    %% Arrows from async_client to test blocks\n    async_client --&gt; test\n    async_session --&gt; test\n\n    async_client_2 --&gt; test_2\n    async_session_2 --&gt; test_2\n    async_client_n --&gt; test_n\n    async_session_n --&gt; test_n\n\n\n    %% Style the nodes with rounded corners\n    classDef fixtureStyle rx:10, ry:10;\n\n    %% Style the nodes\n    class postgres_container,async_session,async_client,test fixtureStyle;\n    class async_session_2,async_client_2,test_2 fixtureStyle;\n    class async_session_n,async_client_n,test_n fixtureStyle;</code></pre> <p>Running the tests again, we should observe that the total time to run all tests decreases to around 4 seconds, with a median of less than one second per test.</p> <pre><code>tests/test_routes.py::test_get_all_tickets_success PASSED               [ 16%]\ntests/test_routes.py::test_get_all_tickets_when_empty PASSED            [ 33%]\ntests/test_routes.py::test_create_ticket_success PASSED                 [ 50%]\ntests/test_routes.py::test_buy_ticket_success PASSED                    [ 66%]\ntests/test_routes.py::test_buy_ticket_when_ticket_not_found PASSED      [ 83%]\ntests/test_routes.py::test_buy_ticket_when_already_sold PASSED          [100%]\n\n============================================= 6 passed in 3.94s =============================================\n</code></pre> Documentation reference links <ul> <li>Scope: sharing fixtures across classes, modules, packages or session</li> <li>API reference</li> <li>Higher-scoped fixtures are executed first</li> </ul>"},{"location":"#final-version-of-test-fixtures","title":"Final version of test fixtures","text":"<p>The final <code>conftest.py</code> is presented below:</p> tests/conftest.py<pre><code>from collections.abc import AsyncGenerator, Generator\nfrom typing import Literal\n\nimport pytest\nfrom httpx import ASGITransport, AsyncClient\nfrom sqlalchemy.ext.asyncio import (\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\nfrom testcontainers.postgres import PostgresContainer\n\nfrom src.app import app\nfrom src.database import get_session\nfrom src.models import Base\n\n\n@pytest.fixture(scope='session')\ndef anyio_backend() -&gt; Literal['asyncio']:\n    return 'asyncio'\n\n\n@pytest.fixture(scope='session')\ndef postgres_container(\n    anyio_backend: Literal['asyncio'],\n) -&gt; Generator[PostgresContainer, None, None]:\n    with PostgresContainer('postgres:16', driver='asyncpg') as postgres:\n        yield postgres\n\n\n@pytest.fixture\nasync def async_session(\n    postgres_container: PostgresContainer,\n) -&gt; AsyncGenerator[AsyncSession, None]:\n    db_url = postgres_container.get_connection_url()\n    async_engine = create_async_engine(db_url)\n\n    async with async_engine.begin() as conn:\n        await conn.run_sync(Base.metadata.drop_all)\n        await conn.run_sync(Base.metadata.create_all)\n\n    async_session = async_sessionmaker(\n        bind=async_engine,\n        expire_on_commit=False,\n        class_=AsyncSession,\n    )\n\n    async with async_session() as session:\n        yield session\n\n    await async_engine.dispose()\n\n\n@pytest.fixture\nasync def async_client(\n    async_session: AsyncSession,\n) -&gt; AsyncGenerator[AsyncClient, None]:\n    app.dependency_overrides[get_session] = lambda: async_session\n    _transport = ASGITransport(app=app)\n\n    async with AsyncClient(\n        transport=_transport, base_url='http://test', follow_redirects=True\n    ) as client:\n        yield client\n\n    app.dependency_overrides.clear()\n</code></pre>"}]}